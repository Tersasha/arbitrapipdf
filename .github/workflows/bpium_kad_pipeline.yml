name: Bpium KAD Pipeline (44 -> 45 PdfText)

on:
  workflow_dispatch:
    inputs:
      track_record_id:
        description: "Bpium catalog 44 record id to process (optional). If empty, auto-pick SyncEnabled=true"
        required: false
        default: ""
      max_tracks_per_run:
        description: "Max tracking records (catalog 44) per run"
        required: true
        default: "100"
      max_parser_api_calls:
        description: "Max parser-api calls per run (budget)"
        required: true
        default: "50"
      max_cases_per_track:
        description: "Max cases to upsert per tracking record"
        required: true
        default: "50"
      rolling_max_pages:
        description: "Max pages to scan in rolling mode (last 6 months)"
        required: true
        default: "3"
      dry_run:
        description: "Do not write to Bpium (true/false)"
        required: true
        default: "false"
      debug:
        description: "Verbose output (true/false)"
        required: true
        default: "false"

permissions:
  contents: read

concurrency:
  group: bpium-kad-pipeline
  cancel-in-progress: false

jobs:
  pipeline:
    runs-on: ubuntu-24.04
    timeout-minutes: 15
    env:
      PIPELINE_ROLLING_MONTHS: "6"
      PIPELINE_SOURCE: "parser-api/kad"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run pipeline
        shell: bash
        env:
          BPIUM_DOMAIN: ${{ secrets.BPIUM_DOMAIN }}
          BPIUM_LOGIN: ${{ secrets.BPIUM_LOGIN }}
          BPIUM_PASSWORD: ${{ secrets.BPIUM_PASSWORD }}
          PARSER_API_KEY: ${{ secrets.PARSER_API_KEY }}
        run: |
          set -euo pipefail

          TRACK="${{ github.event.inputs.track_record_id || '' }}"
          MAX_TRACKS="${{ github.event.inputs.max_tracks_per_run || '' }}"
          MAX_CALLS="${{ github.event.inputs.max_parser_api_calls || '' }}"
          MAX_CASES="${{ github.event.inputs.max_cases_per_track || '' }}"
          ROLL_PAGES="${{ github.event.inputs.rolling_max_pages || '' }}"
          DRY="${{ github.event.inputs.dry_run || '' }}"
          DEBUG="${{ github.event.inputs.debug || '' }}"

          # Defaults for schedule-trigger runs
          if [ -z "$MAX_TRACKS" ]; then MAX_TRACKS="100"; fi
          if [ -z "$MAX_CALLS" ]; then MAX_CALLS="50"; fi
          if [ -z "$MAX_CASES" ]; then MAX_CASES="50"; fi
          if [ -z "$ROLL_PAGES" ]; then ROLL_PAGES="3"; fi
          if [ -z "$DRY" ]; then DRY="false"; fi
          if [ -z "$DEBUG" ]; then DEBUG="false"; fi

          ARGS=(--max-tracks-per-run "$MAX_TRACKS" --max-parser-api-calls "$MAX_CALLS" --max-cases-per-track "$MAX_CASES" --rolling-max-pages "$ROLL_PAGES")
          if [ -n "$TRACK" ]; then ARGS+=(--track-record-id "$TRACK"); fi
          if [ "$DRY" = "true" ]; then ARGS+=(--dry-run); fi
          if [ "$DEBUG" = "true" ]; then ARGS+=(--debug); fi

          python bpium_kad_pipeline_worker.py "${ARGS[@]}" | tee pipeline_out.json

          # Emit token/call usage summary into logs and Job Summary.
          python - <<'PY'
          import json, os
          p = "pipeline_out.json"
          with open(p, "r", encoding="utf-8") as f:
              d = json.load(f)
          api = int(d.get("apiCalls") or 0)
          search = int(d.get("searchCalls") or 0)
          details = int(d.get("detailsCalls") or 0)
          pdf = int(d.get("pdfCalls") or 0)
          processed = d.get("casesUpserted")
          ok = d.get("pdfOk")
          empty = d.get("pdfEmpty")
          err = d.get("pdfErr")
          enrich_ok = d.get("enrichOk")
          enrich_skip = d.get("enrichSkip")
          enrich_err = d.get("enrichErr")
          line = (
              f"parser-api calls used: {api} (search={search}, details={details}, pdf={pdf}); "
              f"casesUpserted={processed}; pdf ok/empty/err={ok}/{empty}/{err}; "
              f"enrich ok/skip/err={enrich_ok}/{enrich_skip}/{enrich_err}"
          )
          print(line)
          summ = os.environ.get("GITHUB_STEP_SUMMARY")
          if summ:
              with open(summ, "a", encoding="utf-8") as sf:
                  sf.write("### Parser-API budget\\n")
                  sf.write(line + "\\n")
          PY
